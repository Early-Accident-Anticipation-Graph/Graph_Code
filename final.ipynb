{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO model loaded.\n"
     ]
    }
   ],
   "source": [
    "def load_yolo_model(cfg_path, weights_path, names_path):\n",
    "    net = cv2.dnn.readNet(weights_path, cfg_path)\n",
    "    with open(names_path, 'r') as f:\n",
    "        classes = f.read().strip().split('\\n')\n",
    "    return net, classes\n",
    "\n",
    "# Paths to YOLO files\n",
    "cfg_path = 'yolov3.cfg'\n",
    "weights_path = 'yolov3.weights'\n",
    "names_path = 'coco.names'\n",
    "\n",
    "# Load YOLO model\n",
    "yolo_model, classes = load_yolo_model(cfg_path, weights_path, names_path)\n",
    "print(\"YOLO model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(net, classes, frame, conf_threshold=0.5, nms_threshold=0.4):\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    layer_names = net.getLayerNames()\n",
    "    output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    detections = net.forward(output_layers)\n",
    "\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "    h, w = frame.shape[:2]\n",
    "\n",
    "    for output in detections:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > conf_threshold:\n",
    "                center_x = int(detection[0] * w)\n",
    "                center_y = int(detection[1] * h)\n",
    "                width = int(detection[2] * w)\n",
    "                height = int(detection[3] * h)\n",
    "                x = int(center_x - width / 2)\n",
    "                y = int(center_y - height / 2)\n",
    "                boxes.append([x, y, x + width, y + height])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "    filtered_boxes = []\n",
    "    if len(indices) > 0:\n",
    "        for i in indices.flatten():\n",
    "            box = boxes[i]\n",
    "            filtered_boxes.append(box + [confidences[i], class_ids[i]])\n",
    "\n",
    "    return filtered_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(video_path, yolo_model, classes, output_dir, target_fps=20):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_features = []\n",
    "    box_features_list = []\n",
    "    detections = []\n",
    "    labels = []\n",
    "    frame_ids = []\n",
    "\n",
    "    frame_count = 0\n",
    "    saved_frame_indices = [0, 10, 20, 30, 40]  # Indices of frames to save with bounding boxes\n",
    "\n",
    "    original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_interval = int(original_fps / target_fps)\n",
    "\n",
    "    while cap.isOpened() and frame_count < 50:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % frame_interval == 0:\n",
    "            # Extract frame-level features (using a CNN, here we just flatten the frame as a placeholder)\n",
    "            frame_feature = cv2.resize(frame, (224, 224)).flatten()[:4096]  # Resize to ensure it fits 4096 elements\n",
    "            frame_features.append(frame_feature)\n",
    "\n",
    "            # Detect objects\n",
    "            boxes = detect_objects(yolo_model, classes, frame)\n",
    "            if len(boxes) > 19:\n",
    "                boxes = boxes[:19]  # Ensure only 19 boxes are considered\n",
    "\n",
    "            # Create box-level features (using the same placeholder approach for now)\n",
    "            box_features = []\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2, _, _ = box\n",
    "                box_frame = frame[y1:y2, x1:x2]\n",
    "                if box_frame.size > 0:\n",
    "                    box_feature = cv2.resize(box_frame, (64, 64)).flatten()[:4096]\n",
    "                    box_features.append(box_feature)\n",
    "                else:\n",
    "                    box_features.append(np.zeros(4096))  # In case of invalid box\n",
    "\n",
    "            while len(box_features) < 19:\n",
    "                box_features.append(np.zeros(4096))  # Pad with zero features if less than 19 boxes\n",
    "\n",
    "            box_features_list.append(box_features)\n",
    "            # Convert boxes to a fixed size array\n",
    "            while len(boxes) < 19:\n",
    "                boxes.append([0, 0, 0, 0, 0.0, -1])  # Pad with default values if less than 19 boxes\n",
    "            detections.append(np.array(boxes))\n",
    "\n",
    "            # Save frames with bounding boxes\n",
    "            if len(frame_features) - 1 in saved_frame_indices:\n",
    "                for box in boxes:\n",
    "                    x1, y1, x2, y2, confidence, class_id = box\n",
    "                    label = f\"{classes[class_id]}: {confidence:.2f}\"\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                output_frame_path = os.path.join(output_dir, f\"frame_{len(frame_features) - 1}.jpg\")\n",
    "                cv2.imwrite(output_frame_path, frame)\n",
    "\n",
    "            # Assign a label (placeholder, replace with actual logic)\n",
    "            label = [1, 0] if len(frame_features) % 2 == 0 else [0, 1]  # Replace with actual condition\n",
    "            labels.append(label)\n",
    "\n",
    "            # Collect frame IDs (placeholder, replace with actual video name logic)\n",
    "            frame_ids.append(f'frame_{len(frame_features) - 1}')  # Replace with actual frame ID or video ID logic\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Ensure we have exactly 50 frames\n",
    "    while len(frame_features) < 50:\n",
    "        frame_features.append(np.zeros(4096))\n",
    "        detections.append(np.array([[0, 0, 0, 0, 0.0, -1]] * 19))\n",
    "        box_features_list.append([np.zeros(4096)] * 19)\n",
    "        labels.append([0, 1])\n",
    "        frame_ids.append(f'frame_{len(frame_features)}')\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    frame_features = np.array(frame_features).reshape((50, 1, 4096))\n",
    "    box_features = np.array(box_features_list).reshape((50, 19, 4096))\n",
    "    detections = np.array(detections).reshape((50, 19, 6))\n",
    "    labels = np.array(labels)\n",
    "    frame_ids = np.array(frame_ids)\n",
    "\n",
    "    # Combine frame-level and box-level features\n",
    "    combined_features = np.concatenate((frame_features, box_features), axis=1)\n",
    "\n",
    "    return combined_features, detections, labels, frame_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Directory to save frames with bounding boxes\u001b[39;00m\n\u001b[1;32m      2\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_frames\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mmakedirs(output_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# Directory to save frames with bounding boxes\n",
    "output_dir = 'output_frames'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the video\n",
    "video_path = 'input_video.mp4'\n",
    "data, det, labels, ID = process_video(video_path, yolo_model, classes, output_dir, target_fps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data: (50, 20, 4096)\n",
      "Size of det: (50, 19, 6)\n",
      "Size of labels: (50, 2)\n",
      "Size of ID: (50,)\n"
     ]
    }
   ],
   "source": [
    "# Print the sizes of the arrays\n",
    "print(\"Size of data:\", data.shape)\n",
    "print(\"Size of det:\", det.shape)\n",
    "print(\"Size of labels:\", labels.shape)\n",
    "print(\"Size of ID:\", ID.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPZ file successfully created.\n"
     ]
    }
   ],
   "source": [
    "# Save to .npz file\n",
    "np.savez('output_data.npz', data=data, det=det, labels=labels, ID=ID)\n",
    "print(\"NPZ file successfully created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data: (50, 20, 4096)\n",
      "Size of det: (50, 19, 6)\n",
      "Size of labels: (50, 2)\n",
      "Size of ID: (50,)\n"
     ]
    }
   ],
   "source": [
    "def read_npz_file(npz_file_path):\n",
    "    # Load the .npz file\n",
    "    npzfile = np.load(npz_file_path)\n",
    "\n",
    "    # Print the sizes of the available arrays\n",
    "    for array_name in npzfile.files:\n",
    "        array = npzfile[array_name]\n",
    "        print(f\"Size of {array_name}: {array.shape}\")\n",
    "\n",
    "# Path to the .npz file\n",
    "npz_file_path = 'output_data.npz'\n",
    "\n",
    "# Read and print sizes of arrays in the .npz file\n",
    "read_npz_file(npz_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
